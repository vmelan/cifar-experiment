{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import libraries & packages</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.layers import Input, Dense, Flatten, Lambda\n",
    "from keras.layers import Conv2D, Activation, AveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "PATH_DATA = \"./SMILEsmileD/SMILEs/\"\n",
    "\n",
    "directory_positive = os.fsencode(PATH_DATA + \"positives/positives7/\")\n",
    "\n",
    "for file in os.listdir(directory_positive):\n",
    "    filename = os.fsdecode(file)\n",
    "    img = cv2.cvtColor(cv2.imread(PATH_DATA + \"positives/positives7/\" + filename), \\\n",
    "                       cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, (32, 32))\n",
    "    img = img_to_array(img)\n",
    "    data.append(img)\n",
    "    \n",
    "    label = \"positive\"\n",
    "    labels.append(label)\n",
    "\n",
    "directory_negative = os.fsencode(PATH_DATA + \"negatives/negatives7/\")\n",
    "\n",
    "for file in os.listdir(directory_negative):\n",
    "    filename = os.fsdecode(file)\n",
    "    img = cv2.cvtColor(cv2.imread(PATH_DATA + \"negatives/negatives7/\" + filename), \\\n",
    "                       cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, (32, 32))\n",
    "    img = img_to_array(img)\n",
    "    data.append(img)\n",
    "    \n",
    "    label = \"negative\"\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data preprocessing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the raw pxel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=np.float32) / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Convert the labels from strings to vectors\n",
    "le = LabelEncoder().fit(labels)\n",
    "labels = to_categorical(le.transform(labels), 2) # one hot vector\n",
    "\n",
    "# Account for skew in the labbeled data\n",
    "classTotals = labels.sum(axis=0) # total # of examples per class\n",
    "classWeight = classTotals.max() / classTotals # scaling these totals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train/test split</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stratify argument will make sure that the test split has the same proportion of positives and negatives samples than the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, \\\n",
    "                                                    test_size=0.2, \\\n",
    "                                                    stratify=labels, \\\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Building model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeNet_model(input_shape=(32, 32, 1), num_classes=2):\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape, name=\"Main_input\")\n",
    "    \n",
    "    # 1st CONV LAYER : kernel (5x5), strides(1, 1), 6 filters, no pad\n",
    "    X = Conv2D(filters=6, kernel_size=(5, 5), strides=(1, 1), \\\n",
    "               kernel_initializer=glorot_uniform(seed=0), \\\n",
    "               padding=\"valid\", \\\n",
    "               name=\"Conv_1\")(X_input)\n",
    "    # Add non linearity with Rectified Linear Unit (ReLU)\n",
    "    X = Activation('tanh', name=\"Tanh_1\")(X)\n",
    "    # Average Pooling \n",
    "    X = AveragePooling2D(pool_size=(2, 2), name=\"Avg_Pool_1\")(X)\n",
    "    \n",
    "    # 2nd CONV LAYER : kernel (5x5), strides (1, 1), 16 filters, no pad\n",
    "    X = Conv2D(filters=16, kernel_size=(5, 5), strides=(1, 1), \\\n",
    "               kernel_initializer=glorot_uniform(seed=0), \\\n",
    "               padding=\"valid\", \\\n",
    "               name=\"Conv_2\")(X)\n",
    "    X = Activation('tanh', name=\"Tanh_2\")(X)\n",
    "    X = AveragePooling2D(pool_size=(2, 2), name=\"Avg_Pool_2\")(X)\n",
    "    \n",
    "    # 3rd CONV LAYER : kernel (5x5), strides (1, 1), 16 filters, no pad\n",
    "    X = Conv2D(filters=120, kernel_size=(5, 5), strides=(1, 1), \\\n",
    "               kernel_initializer=glorot_uniform(seed=0), \\\n",
    "               padding=\"valid\", \\\n",
    "               name=\"Conv_3\")(X)\n",
    "    \n",
    "    # Flatten\n",
    "    X = Flatten(name=\"Flatten\")(X)\n",
    "    \n",
    "    # Fully connected layer 1: 84 units\n",
    "    X = Dense(84, name=\"FC_1\")(X)\n",
    "    X = Activation('tanh', name=\"Tanh_3\")(X)\n",
    "    \n",
    "    # Output layer\n",
    "    X = Dense(num_classes, name=\"Output\")(X)\n",
    "\n",
    "    # Custom activation function (Radial Basis Function - RBF)\n",
    "    l2_norm = lambda a, b: K.sqrt(K.sum(((a - b) ** 2), axis=0, keepdims=True))\n",
    "    def rbf(x, gamma=1.0):\n",
    "         return K.exp(-1 * gamma * l2_norm(x[0], x[1]) ** 2)    \n",
    "    \n",
    "    X = Activation(rbf)(X)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=X_input, outputs=X, name=\"LeNet ConvNet\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a peek at the overall structure we just made by calling the method <i>summary()</i>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Main_input (InputLayer)      (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "Conv_1 (Conv2D)              (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "Tanh_1 (Activation)          (None, 28, 28, 6)         0         \n",
      "_________________________________________________________________\n",
      "Avg_Pool_1 (AveragePooling2D (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "Tanh_2 (Activation)          (None, 10, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "Avg_Pool_2 (AveragePooling2D (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv2D)              (None, 1, 1, 120)         48120     \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "FC_1 (Dense)                 (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "Tanh_3 (Activation)          (None, 84)                0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 2)                 170       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 61,026\n",
      "Trainable params: 61,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Compile Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "logits and labels must have the same shape ((1,) vs (?, ?))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36mmerge_with\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    554\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_same_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m         \u001b[0mnew_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36massert_same_rank\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    599\u001b[0m         raise ValueError(\"Shapes %s and %s must have the same rank\" % (self,\n\u001b[1;32m--> 600\u001b[1;33m                                                                        other))\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shapes (?, ?) and (1,) must have the same rank",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py\u001b[0m in \u001b[0;36msigmoid_cross_entropy_with_logits\u001b[1;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m       \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36mmerge_with\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    560\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shapes %s and %s are not compatible\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shapes (?, ?) and (1,) are not compatible",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-2fb23f712528>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0madam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madam\u001b[0m\u001b[1;33m,\u001b[0m               \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m               \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[0;32m    858\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m                     output_loss = weighted_loss(y_true, y_pred,\n\u001b[1;32m--> 860\u001b[1;33m                                                 sample_weight, mask)\n\u001b[0m\u001b[0;32m    861\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_tensors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mweighted\u001b[1;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[0;32m    457\u001b[0m         \"\"\"\n\u001b[0;32m    458\u001b[0m         \u001b[1;31m# score_array has ndim >= 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m         \u001b[0mscore_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    460\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m             \u001b[1;31m# Cast the mask to floatX to avoid float64 upcasting in theano\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\losses.py\u001b[0m in \u001b[0;36mbinary_crossentropy\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbinary_crossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_crossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mbinary_crossentropy\u001b[1;34m(target, output, from_logits)\u001b[0m\n\u001b[0;32m   2951\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2952\u001b[0m     return tf.nn.sigmoid_cross_entropy_with_logits(labels=target,\n\u001b[1;32m-> 2953\u001b[1;33m                                                    logits=output)\n\u001b[0m\u001b[0;32m   2954\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py\u001b[0m in \u001b[0;36msigmoid_cross_entropy_with_logits\u001b[1;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m       raise ValueError(\"logits and labels must have the same shape (%s vs %s)\"\n\u001b[1;32m--> 157\u001b[1;33m                        % (logits.get_shape(), labels.get_shape()))\n\u001b[0m\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;31m# The logistic loss formula from above is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: logits and labels must have the same shape ((1,) vs (?, ?))"
     ]
    }
   ],
   "source": [
    "adam = Adam(lr=1e-4)\n",
    "\n",
    "model.compile(optimizer=adam, \\\n",
    "              loss='categorical_crossentropy', \\\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
