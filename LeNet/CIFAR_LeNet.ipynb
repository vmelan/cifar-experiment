{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center; color:MediumSlateBlue;\">LeNet on CIFAR-10 dataset</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import libraries & packages</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Dense, Flatten, Lambda\n",
    "from keras.layers import Conv2D, Activation, AveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.models import model_from_json\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_cifar10(data_path):\n",
    "\n",
    "    train_data = None\n",
    "    train_labels = []\n",
    "    test_data = None\n",
    "    test_labels = None\n",
    "\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        data_dict = unpickle(data_path + \"data_batch_\" + str(i))\n",
    "        if (i == 1):\n",
    "            train_data = data_dict[b'data']\n",
    "        else:\n",
    "            train_data = np.vstack((train_data, data_dict[b'data']))\n",
    "        train_labels += data_dict[b'labels']\n",
    "\n",
    "    test_data_dict = unpickle(data_path + \"test_batch\")\n",
    "    test_data = test_data_dict[b'data']\n",
    "    test_labels = test_data_dict[b'labels']\n",
    "\n",
    "    train_data = train_data.reshape((50000, 3, 32, 32))\n",
    "    train_data = np.rollaxis(train_data, 1, 4)\n",
    "    train_labels = np.array(train_labels)\n",
    "    \n",
    "    test_data = test_data.reshape((10000, 3, 32, 32))\n",
    "    test_data = np.rollaxis(test_data, 1, 4)\n",
    "    test_labels = np.array(test_labels)\n",
    "    \n",
    "    return train_data, train_labels, test_data, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"../cifar-10-batches-py/\"\n",
    "train_data, train_labels, test_data, test_labels = load_cifar10(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape: (50000, 32, 32, 3) train_labels.shape: (50000,)\n",
      "test_data.shape: (10000, 32, 32, 3) test_labels.shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_data.shape:\", train_data.shape, \"train_labels.shape:\", train_labels.shape)\n",
    "print(\"test_data.shape:\", test_data.shape, \"test_labels.shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f0394f2278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data preprocessing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_data(data):\n",
    "    \"\"\" \n",
    "    Scale the row pixel intensities to the range [0, 1]\n",
    "    \"\"\"\n",
    "    data = data.astype(np.float32) / 255.0\n",
    "    return data\n",
    "\n",
    "train_data = scale_data(train_data)\n",
    "test_data = scale_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_labels(label_data):\n",
    "    \"\"\"\n",
    "    One hot encode the labels\n",
    "    \"\"\"\n",
    "    label_data = to_categorical(label_data, num_classes=10)\n",
    "    \n",
    "    return label_data\n",
    "\n",
    "train_labels = one_hot_labels(train_labels)\n",
    "test_labels = one_hot_labels(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 10), (10000, 10))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train/validation split</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (45000, 32, 32, 3) y_train.shape (45000, 10)\n",
      "X_valid.shape: (5000, 32, 32, 3) y_valid.shape (5000, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train_data, train_labels, \\\n",
    "                                                      test_size=0.1, \\\n",
    "                                                      random_state=42)\n",
    "\n",
    "print(\"X_train.shape:\", X_train.shape, \"y_train.shape\", y_train.shape)\n",
    "print(\"X_valid.shape:\", X_valid.shape, \"y_valid.shape\", y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Building LeNet model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_gray(image):\n",
    "    return tf.image.rgb_to_grayscale(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LeNet_model(input_shape, num_classes):\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(shape=input_shape, name=\"Input\")\n",
    "    \n",
    "    X = Lambda(convert_gray, input_shape=(32, 32, 3), output_shape=(32, 32, 1), name=\"Grayscale\")(X_input)\n",
    "    \n",
    "    # 1st CONV LAYER: # filters->6; filter size->(5, 5); no pad;  \n",
    "    X = Conv2D(filters=6, kernel_size=(5, 5), strides=(1, 1), \\\n",
    "               kernel_initializer=glorot_uniform(seed=0), \\\n",
    "               padding=\"valid\", \\\n",
    "               name=\"Conv_1\")(X)\n",
    "    # Add non linearity activation function with Rectified Linear Unit (ReLU)\n",
    "    X = Activation(\"tanh\", name=\"Tanh_1\")(X)\n",
    "    # Average Pooling Layer\n",
    "    X = AveragePooling2D(pool_size=(2, 2), name=\"AvgPool_1\")(X)\n",
    "    \n",
    "    # 2nd CONV LAYER: #filters->16; filter size->(5, 5); no pad\n",
    "    X = Conv2D(filters=16, kernel_size=(5, 5), strides=(1, 1), \\\n",
    "               kernel_initializer=glorot_uniform(seed=0), \\\n",
    "               padding=\"valid\", \\\n",
    "               name=\"Conv_2\")(X)\n",
    "    X = Activation(\"tanh\", name=\"Tanh_2\")(X)\n",
    "    X = AveragePooling2D(pool_size=(2, 2), name=\"AvgPool_2\")(X)\n",
    "    \n",
    "    # 3rd CONV LAYER: #filters->120; filter size->(5, 5); no pad\n",
    "    X = Conv2D(filters=120, kernel_size=(5, 5), strides=(1, 1), \\\n",
    "               kernel_initializer=glorot_uniform(seed=0), \\\n",
    "               padding=\"valid\", \\\n",
    "               name=\"Conv_3\")(X)\n",
    "    X = Activation(\"tanh\", name=\"Tanh_3\")(X)\n",
    "    # Flatten\n",
    "    X = Flatten(name=\"Flatten\")(X)\n",
    "    \n",
    "    # 1st Fully Connected layer (FC)\n",
    "    X = Dense(84, name=\"FC_1\")(X)\n",
    "    X = Activation(\"tanh\", name=\"Tanh_4\")(X)\n",
    "    \n",
    "    # Output with Gaussian connections\n",
    "    X = Dense(num_classes, name=\"FC_2\")(X)\n",
    "\n",
    "    def gaussian(x):\n",
    "        return K.exp(-K.pow(x, 2))\n",
    "    \n",
    "    X = Activation(gaussian, name=\"rbf\")(X)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=X_input, outputs=X, name=\"LeNet\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LeNet_model(input_shape=(32, 32, 3), num_classes= y_train.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a peek at the overall structure we just made by calling the method <i>summary()</i>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "Grayscale (Lambda)           (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "Conv_1 (Conv2D)              (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "Tanh_1 (Activation)          (None, 28, 28, 6)         0         \n",
      "_________________________________________________________________\n",
      "AvgPool_1 (AveragePooling2D) (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "Tanh_2 (Activation)          (None, 10, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "AvgPool_2 (AveragePooling2D) (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv2D)              (None, 1, 1, 120)         48120     \n",
      "_________________________________________________________________\n",
      "Tanh_3 (Activation)          (None, 1, 1, 120)         0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "FC_1 (Dense)                 (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "Tanh_4 (Activation)          (None, 84)                0         \n",
      "_________________________________________________________________\n",
      "FC_2 (Dense)                 (None, 10)                850       \n",
      "_________________________________________________________________\n",
      "rbf (Activation)             (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Compile Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=1e-4)\n",
    "\n",
    "model.compile(optimizer=adam, \\\n",
    "              loss='categorical_crossentropy', \\\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create checkpoint</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = \"./checkpoint/weights_best_lenet.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, \\\n",
    "                             monitor=\"val_acc\", \\\n",
    "                             verbose=0, \\\n",
    "                             save_best_only=True, \\\n",
    "                             mode=\"max\")\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Fit the model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "45000/45000 [==============================] - 30s 656us/step - loss: 2.1657 - acc: 0.1954 - val_loss: 2.1224 - val_acc: 0.2304\n",
      "Epoch 2/100\n",
      "45000/45000 [==============================] - 30s 659us/step - loss: 2.0773 - acc: 0.2622 - val_loss: 2.0894 - val_acc: 0.2580\n",
      "Epoch 3/100\n",
      "45000/45000 [==============================] - 29s 638us/step - loss: 2.0565 - acc: 0.2700 - val_loss: 2.0556 - val_acc: 0.2732\n",
      "Epoch 4/100\n",
      "45000/45000 [==============================] - 29s 644us/step - loss: 2.0378 - acc: 0.2792 - val_loss: 2.0517 - val_acc: 0.2578\n",
      "Epoch 5/100\n",
      "45000/45000 [==============================] - 29s 641us/step - loss: 2.0172 - acc: 0.2870 - val_loss: 2.0232 - val_acc: 0.2830\n",
      "Epoch 6/100\n",
      "45000/45000 [==============================] - 29s 638us/step - loss: 1.9917 - acc: 0.2974 - val_loss: 2.0022 - val_acc: 0.2864\n",
      "Epoch 7/100\n",
      "45000/45000 [==============================] - 29s 646us/step - loss: 1.9635 - acc: 0.3064 - val_loss: 1.9727 - val_acc: 0.3010\n",
      "Epoch 8/100\n",
      "45000/45000 [==============================] - 29s 651us/step - loss: 1.9336 - acc: 0.3153 - val_loss: 1.9500 - val_acc: 0.3040\n",
      "Epoch 9/100\n",
      "45000/45000 [==============================] - 29s 646us/step - loss: 1.9101 - acc: 0.3201 - val_loss: 1.9194 - val_acc: 0.3110\n",
      "Epoch 10/100\n",
      "45000/45000 [==============================] - 29s 644us/step - loss: 1.8819 - acc: 0.3319 - val_loss: 1.8904 - val_acc: 0.3238\n",
      "Epoch 11/100\n",
      "45000/45000 [==============================] - 29s 647us/step - loss: 1.8597 - acc: 0.3379 - val_loss: 1.8695 - val_acc: 0.3310\n",
      "Epoch 12/100\n",
      "45000/45000 [==============================] - 29s 644us/step - loss: 1.8361 - acc: 0.3459 - val_loss: 1.8644 - val_acc: 0.3310\n",
      "Epoch 13/100\n",
      "45000/45000 [==============================] - 29s 646us/step - loss: 1.8186 - acc: 0.3516 - val_loss: 1.8366 - val_acc: 0.3420\n",
      "Epoch 14/100\n",
      "45000/45000 [==============================] - 29s 643us/step - loss: 1.8035 - acc: 0.3567 - val_loss: 1.8245 - val_acc: 0.3400\n",
      "Epoch 15/100\n",
      "45000/45000 [==============================] - 29s 649us/step - loss: 1.7837 - acc: 0.3654 - val_loss: 1.8129 - val_acc: 0.3500\n",
      "Epoch 16/100\n",
      "45000/45000 [==============================] - 29s 650us/step - loss: 1.7677 - acc: 0.3686 - val_loss: 1.8130 - val_acc: 0.3560\n",
      "Epoch 17/100\n",
      "45000/45000 [==============================] - 29s 649us/step - loss: 1.7515 - acc: 0.3767 - val_loss: 1.7876 - val_acc: 0.3578\n",
      "Epoch 18/100\n",
      "45000/45000 [==============================] - 29s 652us/step - loss: 1.7372 - acc: 0.3797 - val_loss: 1.7739 - val_acc: 0.3660\n",
      "Epoch 19/100\n",
      "45000/45000 [==============================] - 29s 652us/step - loss: 1.7224 - acc: 0.3882 - val_loss: 1.7524 - val_acc: 0.3756\n",
      "Epoch 20/100\n",
      "45000/45000 [==============================] - 30s 657us/step - loss: 1.7094 - acc: 0.3933 - val_loss: 1.7420 - val_acc: 0.3772\n",
      "Epoch 21/100\n",
      "45000/45000 [==============================] - 29s 655us/step - loss: 1.6943 - acc: 0.3972 - val_loss: 1.7355 - val_acc: 0.3778\n",
      "Epoch 22/100\n",
      "45000/45000 [==============================] - 30s 658us/step - loss: 1.6863 - acc: 0.4015 - val_loss: 1.7227 - val_acc: 0.3832\n",
      "Epoch 23/100\n",
      "45000/45000 [==============================] - 30s 658us/step - loss: 1.6735 - acc: 0.4052 - val_loss: 1.7110 - val_acc: 0.3854\n",
      "Epoch 24/100\n",
      "45000/45000 [==============================] - 29s 652us/step - loss: 1.6609 - acc: 0.4097 - val_loss: 1.7266 - val_acc: 0.3860\n",
      "Epoch 25/100\n",
      "45000/45000 [==============================] - 30s 661us/step - loss: 1.6512 - acc: 0.4124 - val_loss: 1.7084 - val_acc: 0.3834\n",
      "Epoch 26/100\n",
      "45000/45000 [==============================] - 30s 667us/step - loss: 1.6447 - acc: 0.4152 - val_loss: 1.6973 - val_acc: 0.3928\n",
      "Epoch 27/100\n",
      "45000/45000 [==============================] - 30s 656us/step - loss: 1.6332 - acc: 0.4225 - val_loss: 1.6852 - val_acc: 0.3948\n",
      "Epoch 28/100\n",
      "45000/45000 [==============================] - 30s 660us/step - loss: 1.6257 - acc: 0.4222 - val_loss: 1.6728 - val_acc: 0.3982\n",
      "Epoch 29/100\n",
      "45000/45000 [==============================] - 30s 659us/step - loss: 1.6166 - acc: 0.4259 - val_loss: 1.6718 - val_acc: 0.4008\n",
      "Epoch 30/100\n",
      "45000/45000 [==============================] - 30s 659us/step - loss: 1.6084 - acc: 0.4280 - val_loss: 1.6589 - val_acc: 0.4102\n",
      "Epoch 31/100\n",
      "45000/45000 [==============================] - 30s 660us/step - loss: 1.6023 - acc: 0.4300 - val_loss: 1.6537 - val_acc: 0.4050\n",
      "Epoch 32/100\n",
      "45000/45000 [==============================] - 30s 662us/step - loss: 1.5951 - acc: 0.4346 - val_loss: 1.6433 - val_acc: 0.4120\n",
      "Epoch 33/100\n",
      "45000/45000 [==============================] - 30s 666us/step - loss: 1.5872 - acc: 0.4364 - val_loss: 1.6439 - val_acc: 0.4128\n",
      "Epoch 34/100\n",
      "45000/45000 [==============================] - 28s 631us/step - loss: 1.5825 - acc: 0.4382 - val_loss: 1.6373 - val_acc: 0.4064\n",
      "Epoch 35/100\n",
      "45000/45000 [==============================] - 30s 664us/step - loss: 1.5756 - acc: 0.4410 - val_loss: 1.6480 - val_acc: 0.4096\n",
      "Epoch 36/100\n",
      "45000/45000 [==============================] - 30s 660us/step - loss: 1.5706 - acc: 0.4419 - val_loss: 1.6288 - val_acc: 0.4206\n",
      "Epoch 37/100\n",
      "45000/45000 [==============================] - 30s 666us/step - loss: 1.5650 - acc: 0.4454 - val_loss: 1.6356 - val_acc: 0.4150\n",
      "Epoch 38/100\n",
      "45000/45000 [==============================] - 30s 665us/step - loss: 1.5573 - acc: 0.4465 - val_loss: 1.6190 - val_acc: 0.4186\n",
      "Epoch 39/100\n",
      "45000/45000 [==============================] - 30s 664us/step - loss: 1.5526 - acc: 0.4494 - val_loss: 1.6181 - val_acc: 0.4204\n",
      "Epoch 40/100\n",
      "45000/45000 [==============================] - 30s 670us/step - loss: 1.5496 - acc: 0.4527 - val_loss: 1.6231 - val_acc: 0.4178\n",
      "Epoch 41/100\n",
      "45000/45000 [==============================] - 30s 670us/step - loss: 1.5428 - acc: 0.4524 - val_loss: 1.6216 - val_acc: 0.4202\n",
      "Epoch 42/100\n",
      "45000/45000 [==============================] - 30s 673us/step - loss: 1.5350 - acc: 0.4560 - val_loss: 1.6084 - val_acc: 0.4258\n",
      "Epoch 43/100\n",
      "45000/45000 [==============================] - 30s 671us/step - loss: 1.5338 - acc: 0.4582 - val_loss: 1.6034 - val_acc: 0.4248\n",
      "Epoch 44/100\n",
      "45000/45000 [==============================] - 31s 680us/step - loss: 1.5262 - acc: 0.4591 - val_loss: 1.6108 - val_acc: 0.4268\n",
      "Epoch 45/100\n",
      "45000/45000 [==============================] - 30s 671us/step - loss: 1.5204 - acc: 0.4608 - val_loss: 1.6051 - val_acc: 0.4270\n",
      "Epoch 46/100\n",
      "45000/45000 [==============================] - 30s 674us/step - loss: 1.5175 - acc: 0.4618 - val_loss: 1.5965 - val_acc: 0.4350\n",
      "Epoch 47/100\n",
      "45000/45000 [==============================] - 30s 672us/step - loss: 1.5098 - acc: 0.4643 - val_loss: 1.5962 - val_acc: 0.4362\n",
      "Epoch 48/100\n",
      "45000/45000 [==============================] - 30s 669us/step - loss: 1.5061 - acc: 0.4684 - val_loss: 1.6262 - val_acc: 0.4216\n",
      "Epoch 49/100\n",
      "45000/45000 [==============================] - 30s 677us/step - loss: 1.5021 - acc: 0.4677 - val_loss: 1.5752 - val_acc: 0.4414\n",
      "Epoch 50/100\n",
      "45000/45000 [==============================] - 30s 676us/step - loss: 1.4974 - acc: 0.4661 - val_loss: 1.5825 - val_acc: 0.4366\n",
      "Epoch 51/100\n",
      "45000/45000 [==============================] - 30s 676us/step - loss: 1.4923 - acc: 0.4714 - val_loss: 1.5832 - val_acc: 0.4412\n",
      "Epoch 52/100\n",
      "45000/45000 [==============================] - 31s 679us/step - loss: 1.4893 - acc: 0.4722 - val_loss: 1.5862 - val_acc: 0.4352\n",
      "Epoch 53/100\n",
      "45000/45000 [==============================] - 30s 671us/step - loss: 1.4824 - acc: 0.4743 - val_loss: 1.5694 - val_acc: 0.4374\n",
      "Epoch 54/100\n",
      "45000/45000 [==============================] - 30s 674us/step - loss: 1.4803 - acc: 0.4770 - val_loss: 1.5672 - val_acc: 0.4450\n",
      "Epoch 55/100\n",
      "45000/45000 [==============================] - 30s 669us/step - loss: 1.4758 - acc: 0.4786 - val_loss: 1.5677 - val_acc: 0.4408\n",
      "Epoch 56/100\n",
      "45000/45000 [==============================] - 30s 672us/step - loss: 1.4682 - acc: 0.4788 - val_loss: 1.5694 - val_acc: 0.4438\n",
      "Epoch 57/100\n",
      "45000/45000 [==============================] - 30s 669us/step - loss: 1.4672 - acc: 0.4804 - val_loss: 1.5657 - val_acc: 0.4418\n",
      "Epoch 58/100\n",
      "45000/45000 [==============================] - 30s 676us/step - loss: 1.4609 - acc: 0.4836 - val_loss: 1.5514 - val_acc: 0.4552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "45000/45000 [==============================] - 28s 618us/step - loss: 1.4592 - acc: 0.4846 - val_loss: 1.5584 - val_acc: 0.4516\n",
      "Epoch 60/100\n",
      "45000/45000 [==============================] - 28s 623us/step - loss: 1.4524 - acc: 0.4856 - val_loss: 1.5903 - val_acc: 0.4468\n",
      "Epoch 61/100\n",
      "45000/45000 [==============================] - 28s 618us/step - loss: 1.4494 - acc: 0.4865 - val_loss: 1.5601 - val_acc: 0.4476\n",
      "Epoch 62/100\n",
      "45000/45000 [==============================] - 28s 622us/step - loss: 1.4453 - acc: 0.4880 - val_loss: 1.5494 - val_acc: 0.4546\n",
      "Epoch 63/100\n",
      "45000/45000 [==============================] - 28s 620us/step - loss: 1.4445 - acc: 0.4907 - val_loss: 1.5520 - val_acc: 0.4520\n",
      "Epoch 64/100\n",
      "45000/45000 [==============================] - 28s 621us/step - loss: 1.4372 - acc: 0.4901 - val_loss: 1.5594 - val_acc: 0.4460\n",
      "Epoch 65/100\n",
      "45000/45000 [==============================] - 28s 623us/step - loss: 1.4328 - acc: 0.4945 - val_loss: 1.5523 - val_acc: 0.4570\n",
      "Epoch 66/100\n",
      "45000/45000 [==============================] - 28s 620us/step - loss: 1.4326 - acc: 0.4935 - val_loss: 1.5370 - val_acc: 0.4574\n",
      "Epoch 67/100\n",
      "45000/45000 [==============================] - 28s 624us/step - loss: 1.4253 - acc: 0.4962 - val_loss: 1.5379 - val_acc: 0.4574\n",
      "Epoch 68/100\n",
      "45000/45000 [==============================] - 28s 617us/step - loss: 1.4212 - acc: 0.4974 - val_loss: 1.5412 - val_acc: 0.4614\n",
      "Epoch 69/100\n",
      "45000/45000 [==============================] - 29s 636us/step - loss: 1.4190 - acc: 0.4988 - val_loss: 1.5409 - val_acc: 0.4560\n",
      "Epoch 70/100\n",
      "45000/45000 [==============================] - 29s 653us/step - loss: 1.4149 - acc: 0.5016 - val_loss: 1.5337 - val_acc: 0.4598\n",
      "Epoch 71/100\n",
      "45000/45000 [==============================] - 29s 651us/step - loss: 1.4096 - acc: 0.5032 - val_loss: 1.5451 - val_acc: 0.4578\n",
      "Epoch 72/100\n",
      "45000/45000 [==============================] - 29s 651us/step - loss: 1.4060 - acc: 0.5057 - val_loss: 1.5336 - val_acc: 0.4624\n",
      "Epoch 73/100\n",
      "45000/45000 [==============================] - 30s 661us/step - loss: 1.4052 - acc: 0.5033 - val_loss: 1.5306 - val_acc: 0.4594\n",
      "Epoch 74/100\n",
      "45000/45000 [==============================] - 30s 664us/step - loss: 1.4008 - acc: 0.5052 - val_loss: 1.5278 - val_acc: 0.4688\n",
      "Epoch 75/100\n",
      "45000/45000 [==============================] - 30s 657us/step - loss: 1.3965 - acc: 0.5070 - val_loss: 1.5257 - val_acc: 0.4676\n",
      "Epoch 76/100\n",
      "45000/45000 [==============================] - 30s 658us/step - loss: 1.3949 - acc: 0.5084 - val_loss: 1.5207 - val_acc: 0.4674\n",
      "Epoch 77/100\n",
      "45000/45000 [==============================] - 30s 661us/step - loss: 1.3916 - acc: 0.5096 - val_loss: 1.5270 - val_acc: 0.4682\n",
      "Epoch 78/100\n",
      "45000/45000 [==============================] - 30s 661us/step - loss: 1.3872 - acc: 0.5109 - val_loss: 1.5315 - val_acc: 0.4654\n",
      "Epoch 79/100\n",
      "45000/45000 [==============================] - 30s 657us/step - loss: 1.3854 - acc: 0.5104 - val_loss: 1.5325 - val_acc: 0.4646\n",
      "Epoch 80/100\n",
      "45000/45000 [==============================] - 30s 656us/step - loss: 1.3806 - acc: 0.5120 - val_loss: 1.5191 - val_acc: 0.4682\n",
      "Epoch 81/100\n",
      "45000/45000 [==============================] - 29s 655us/step - loss: 1.3756 - acc: 0.5142 - val_loss: 1.5182 - val_acc: 0.4720\n",
      "Epoch 82/100\n",
      "45000/45000 [==============================] - 30s 660us/step - loss: 1.3715 - acc: 0.5168 - val_loss: 1.5102 - val_acc: 0.4738\n",
      "Epoch 83/100\n",
      "45000/45000 [==============================] - 31s 684us/step - loss: 1.3684 - acc: 0.5194 - val_loss: 1.5269 - val_acc: 0.4670\n",
      "Epoch 84/100\n",
      "45000/45000 [==============================] - 30s 657us/step - loss: 1.3664 - acc: 0.5200 - val_loss: 1.5149 - val_acc: 0.4748\n",
      "Epoch 85/100\n",
      "45000/45000 [==============================] - 29s 637us/step - loss: 1.3632 - acc: 0.5197 - val_loss: 1.5167 - val_acc: 0.4712\n",
      "Epoch 86/100\n",
      "45000/45000 [==============================] - 32s 715us/step - loss: 1.3604 - acc: 0.5207 - val_loss: 1.5223 - val_acc: 0.4654\n",
      "Epoch 87/100\n",
      "45000/45000 [==============================] - 27s 604us/step - loss: 1.3572 - acc: 0.5226 - val_loss: 1.5160 - val_acc: 0.4712\n",
      "Epoch 88/100\n",
      "45000/45000 [==============================] - 27s 597us/step - loss: 1.3558 - acc: 0.5226 - val_loss: 1.5037 - val_acc: 0.4830\n",
      "Epoch 89/100\n",
      "45000/45000 [==============================] - 27s 598us/step - loss: 1.3500 - acc: 0.5238 - val_loss: 1.5115 - val_acc: 0.4800\n",
      "Epoch 90/100\n",
      "45000/45000 [==============================] - 27s 598us/step - loss: 1.3471 - acc: 0.5260 - val_loss: 1.5168 - val_acc: 0.4700\n",
      "Epoch 91/100\n",
      "45000/45000 [==============================] - 27s 599us/step - loss: 1.3460 - acc: 0.5258 - val_loss: 1.4973 - val_acc: 0.4794\n",
      "Epoch 92/100\n",
      "45000/45000 [==============================] - 27s 599us/step - loss: 1.3409 - acc: 0.5274 - val_loss: 1.5039 - val_acc: 0.4738\n",
      "Epoch 93/100\n",
      "45000/45000 [==============================] - 27s 601us/step - loss: 1.3398 - acc: 0.5295 - val_loss: 1.5208 - val_acc: 0.4706\n",
      "Epoch 94/100\n",
      "45000/45000 [==============================] - 27s 599us/step - loss: 1.3350 - acc: 0.5320 - val_loss: 1.5116 - val_acc: 0.4762\n",
      "Epoch 95/100\n",
      "45000/45000 [==============================] - 27s 599us/step - loss: 1.3332 - acc: 0.5317 - val_loss: 1.5303 - val_acc: 0.4658\n",
      "Epoch 96/100\n",
      "45000/45000 [==============================] - 27s 604us/step - loss: 1.3274 - acc: 0.5323 - val_loss: 1.4900 - val_acc: 0.4846\n",
      "Epoch 97/100\n",
      "45000/45000 [==============================] - 27s 603us/step - loss: 1.3266 - acc: 0.5333 - val_loss: 1.5012 - val_acc: 0.4842\n",
      "Epoch 98/100\n",
      "45000/45000 [==============================] - 27s 605us/step - loss: 1.3222 - acc: 0.5354 - val_loss: 1.5103 - val_acc: 0.4752\n",
      "Epoch 99/100\n",
      "45000/45000 [==============================] - 27s 604us/step - loss: 1.3219 - acc: 0.5364 - val_loss: 1.4977 - val_acc: 0.4770\n",
      "Epoch 100/100\n",
      "45000/45000 [==============================] - 27s 604us/step - loss: 1.3191 - acc: 0.5361 - val_loss: 1.4924 - val_acc: 0.4842\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \\\n",
    "                    validation_data=(X_valid, y_valid), \\\n",
    "                    epochs=100, \\\n",
    "                    batch_size=128, \\\n",
    "                    callbacks=callbacks_list, \\\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>Load weights of trained model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./checkpoint/weights_best_lenet.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Compile model (required to make predictions)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=1e-4)\n",
    "\n",
    "model.compile(optimizer=adam, \\\n",
    "              loss='categorical_crossentropy', \\\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Estimate accuracy on test set</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 7s 690us/step\n",
      "acc: 47.92%\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = test_data, test_labels\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
